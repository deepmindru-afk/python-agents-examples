version: '1.0'
description: Index of all LiveKit Agent examples with metadata
total_examples: 45
examples:
- file_path: avatars/hedra/dynamically_created_avatar/agent.py
  title: Dynamically Created Avatar
  category: avatars
  tags:
  - avatar
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create an avatar dynamically in an agent.
  demonstrates:
  - Making parallel calls to an LLM while speaking to the voice agent
  - Creating an avatar dynamically in an agent
  - Creating a new hedra avatar session using a custom image
  - A function tool that uses a docstring to describe the tool for the LLM to use
- file_path: avatars/hedra/education_avatar/agent.py
  title: Education Avatar
  category: avatars
  tags:
  - avatar
  - openai
  - deepgram
  - hedra
  difficulty: advanced
  description: Shows how to create an avatar that can help a user learn about the Fall of the Roman Empire using flash cards
    and quizzes.
  demonstrates:
  - Creating a new hedra avatar session using a custom image
  - Using RPC to send messages to the client for flash cards and quizzes using `perform_rpc`
  - Using `register_rpc_method` to register the RPC methods so that the agent can receive messages from the client
  - Using UserData to store state for the cards and the quizzes
  - Using custom data classes to represent the flash cards and quizzes
- file_path: avatars/tavus/tavus.py
  title: Tavus Avatar
  category: avatars
  tags:
  - avatar
  - openai
  - deepgram
  - tavus
  difficulty: intermediate
  description: Shows how to create a tavus avatar that can help a user learn about the Fall of the Roman Empire using flash
    cards and quizzes.
  demonstrates:
  - Creating a new tavus avatar session
  - Using RPC to send messages to the client for flash cards and quizzes using `perform_rpc`
  - Using `register_rpc_method` to register the RPC methods so that the agent can receive messages from the client
  - Using UserData to store state for the cards and the quizzes
  - Using custom data classes to represent the flash cards and quizzes
- file_path: basics/change_agent_instructions.py
  title: Change Agent Instructions
  category: basics
  tags:
  - instructions
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to change the instructions of an agent.
  demonstrates:
  - Changing agent instructions after the agent has started using `update_instructions`
- file_path: basics/context_variables.py
  title: Context Variables
  category: basics
  tags:
  - context
  - variables
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to give an agent context about the user using simple variables.
  demonstrates:
  - Using context variables from a simple dictionary
- file_path: basics/label_messages.py
  title: Conversation Event Monitoring Agent
  category: basics
  tags:
  - events
  - conversation-monitoring
  - logging
  - deepgram
  - openai
  difficulty: beginner
  description: Shows how to monitor and log conversation events as they occur, useful for debugging and understanding agent-user
    interactions.
  demonstrates:
  - Conversation event handling and logging
- file_path: basics/echo_transcriber_agent.py
  title: Echo Transcriber Agent
  category: basics
  tags:
  - echo
  - transcriber
  - deepgram
  - silero
  difficulty: beginner
  description: Shows how to create an agent that can transcribe audio and echo it back.
  demonstrates:
  - Transcribing audio
  - Echoing audio back that's stored in a buffer
- file_path: basics/exit_message.py
  title: Exit Message
  category: basics
  tags:
  - exit
  - message
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use the `on_exit` method to take an action when the agent exits.
  demonstrates:
  - Use the `on_exit` method to take an action when the agent exits
- file_path: basics/say_in_voice.py
  title: Function Tool Voice Switching Agent
  category: basics
  tags:
  - tts
  - voice-switching
  - function-tools
  - inworld
  - deepgram
  - openai
  difficulty: beginner
  description: Demonstrates how to create an agent that can dynamically switch between different voices during a conversation
    using function tools.
  demonstrates:
  - Dynamic TTS voice switching
  - Function tool integration
  - Multiple TTS provider support (Inworld)
- file_path: basics/interrupts_user.py
  title: Interrupt User
  category: basics
  tags:
  - interrupts
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to interrupt the user if they try to say more than one sentence.
  demonstrates:
  - Using the `stt_node` to read the user's input in real time
  - Setting `allow_interruptions` to `False` to prevent the user from interrupting the agent
- file_path: basics/listen_and_respond.py
  title: Listen and Respond
  category: basics
  tags:
  - listen
  - respond
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to create an agent that can listen to the user and respond.
  demonstrates:
  - This is the most basic agent that can listen to the user and respond. This is a good starting point for any agent.
- file_path: basics/playing_audio.py
  title: Playing Audio
  category: basics
  tags:
  - audio
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to play audio from a file in an agent.
  demonstrates:
  - Playing audio from a file
- file_path: basics/repeater.py
  title: Repeater
  category: basics
  tags:
  - repeater
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to create an agent that can repeat what the user says.
  demonstrates:
  - Using the `on_user_input_transcribed` event to listen to the user's input
  - Using the `say` method to respond to the user with the same input
- file_path: basics/tool_calling.py
  title: Tool Calling
  category: basics
  tags:
  - tool-calling
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use tool calling in an agent.
  demonstrates:
  - Using the most basic form of tool calling in an agent to print to the console
- file_path: egress/recording_agent.py
  title: Recording Agent
  category: egress
  tags:
  - recording
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create an agent that can record the input to a room and save it to a file.
  demonstrates:
  - Using egress to record the input to a room
- file_path: events/basic_event.py
  title: Basic Event
  category: events
  tags:
  - events
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use events in an agent to trigger actions.
  demonstrates:
  - Using events in an agent to trigger actions
  - Using `on` to register an event listener
  - Using `off` to unregister an event listener
  - Using `once` to register an event listener that will only be triggered once
- file_path: events/event_emitters.py
  title: Event Emitters
  category: events
  tags:
  - events
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use event emitters in an agent to trigger actions.
  demonstrates:
  - Using event emitters in an agent to trigger actions like welcome and farewell messages for the sake of example (even though
    there are already events for this)
- file_path: flows/declarative_flow.py
  title: Declarative Flow
  category: flows
  tags:
  - flows
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create a declarative flow using a dictionary of mutliple agents and their transitions.
  demonstrates:
  - Creating a defined flow of agents using a dictionary of mutliple agents and their transitions.
  - Using a function to determine the next agent in the flow.
- file_path: flows/multi_stage_flow.py
  title: Multi-Stage Flow
  category: flows
  tags:
  - flows
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create a multi-stage flow using a series of agents.
  demonstrates:
  - Creating a multi-stage flow using a series of agents.
- file_path: flows/simple_flow.py
  title: Simple Flow
  category: flows
  tags:
  - flows
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to create a simple one-way flow using a series of agents.
  demonstrates:
  - Creating a simple one-way flow using a series of agents that hand off to the next agent in the flow.
- file_path: hardware/pi-zero-transcriber/pi_zero_transcriber.py
  title: Pi Zero Transcriber
  category: hardware
  tags:
  - hardware
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to create a simple transcriber that uses the LiveKit SDK to transcribe audio from the microphone.
  demonstrates:
  - Using the LiveKit SDK to transcribe audio from the microphone.
  - Displaying the transcribed text on a Pirate Audio display on a Raspberry Pi Zero 2 W.
- file_path: home_assistant/homeautomation.py
  title: Home Automation
  category: home-automation
  tags:
  - home-automation
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create an agent that can control home automation devices.
  demonstrates:
  - Using function tools to control home automation devices.
  - Using a wake word to trigger the agent.
- file_path: mcp/agent.py
  title: MCP Agent
  category: mcp
  tags:
  - mcp
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use a LiveKit Agent as an MCP client.
  demonstrates:
  - Connecting to a local MCP server as a client.
  - Connecting to a remote MCP server as a client.
  - Using a function tool to retrieve data from the MCP server.
- file_path: mcp/server.py
  title: MCP Server
  category: mcp
  tags:
  - mcp
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to create an MCP server that can be used to control a LiveKit room.
  demonstrates:
  - Creating an MCP server that can be used to control a LiveKit room.
- file_path: metrics/langfuse_tracing.py
  title: Langfuse Tracing
  category: metrics
  tags:
  - metrics
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the langfuse tracer to trace the agent session.
  demonstrates:
  - Using the langfuse tracer to trace the agent session.
  - Using the metrics_collected event to log metrics to langfuse.
- file_path: metrics/metrics_stt.py
  title: STT Metrics
  category: metrics
  tags:
  - metrics
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use the STT metrics to log metrics to the console.
  demonstrates:
  - Using the STT metrics to log metrics to the console.
  - This includes:
    - Type
    - Label
    - Request ID
    - Timestamp
    - Duration
    - Speech ID
    - Error
- file_path: metrics/metrics_vad.py
  title: VAD Metrics
  category: metrics
  tags:
  - metrics
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to use the VAD metrics to log metrics to the console.
  demonstrates:
  - Using the VAD metrics to log metrics to the console.
  - This includes:
    - Idle Time
    - Inference Duration Total
    - Inference Count
    - Speech ID
    - Error
- file_path: multi-agent/long_or_short_agent.py
  title: Long or Short Agent
  category: multi-agent
  tags:
  - multi-agent
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to create a multi-agent that can switch between a long and short agent using a function tool.
  demonstrates:
  - Creating a multi-agent that can switch between a long and short agent using a function tool.
  - Using a function tool to change the agent.
  - Different agents can have different instructions, models, and tools.
- file_path: pipeline-llm/anthropic_llm.py
  title: Anthropic LLM
  category: pipeline-llm
  tags:
  - pipeline-llm
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Anthropic LLM.
  demonstrates:
  - Using the Anthropic LLM.
- file_path: pipeline-llm/cerebras_llm.py
  title: Cerebras LLM
  category: pipeline-llm
  tags:
  - pipeline-llm
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Cerebras LLM.
  demonstrates:
  - Using the Cerebras LLM.
- file_path: pipeline-llm/google_llm.py
  title: Google LLM
  category: pipeline-llm
  tags:
  - pipeline-llm
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Google LLM.
  demonstrates:
  - Using the Google LLM.
- file_path: pipeline-llm/interrupt_user.py
  title: Interrupt User
  category: pipeline-llm
  tags:
  - pipeline-llm
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to interrupt the user if they've spoken too much.
  demonstrates:
  - Using the `session.say` method to interrupt the user.
  - Using the `allow_interruptions` parameter to prevent the user from interrupting the agent.
  - Once the agent has spoken, it will allow the user to interrupt again.
- file_path: pipeline-stt/diarization.py
  title: Diarization
  category: pipeline-stt
  tags:
  - pipeline-stt
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Speechmatics STT model with diarization.
  demonstrates:
  - Using the Speechmatics STT model with diarization.
  - Allow speakers to label themselves when they're speaking using function tools.
  - Using the `stt_node` method to override the default STT node and add custom logic to detect speaker changes.
- file_path: pipeline-stt/keyword-detection/keyword_detection.py
  title: Keyword Detection
  category: pipeline-stt
  tags:
  - pipeline-stt
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to detect keywords in user speech.
  demonstrates:
  - If the user says a keyword, the agent will log the keyword to the console.
  - Using the `stt_node` method to override the default STT node and add custom logic to detect keywords.
- file_path: pipeline-stt/transcriber/transcriber.py
  title: Transcriber
  category: pipeline-stt
  tags:
  - pipeline-stt
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to transcribe user speech to text without TTS or an LLM.
  demonstrates:
  - Saving transcripts to a file.
  - An Agent that does not have TTS or an LLM. This is STT only.
- file_path: pipeline-tts/cartesia_tts.py
  title: Cartesia TTS
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Cartesia TTS model.
  demonstrates:
  - Using the Cartesia TTS model.
- file_path: pipeline-tts/changing_language/elevenlabs_change_language.py
  title: ElevenLabs Change Language
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the ElevenLabs TTS model to change the language of the agent.
  demonstrates:
  - Using the `tts.update_options` method to change the language of the agent.
  - Allowing agents to self-update their own options using function tools.
- file_path: pipeline-tts/elevenlabs_tts.py
  title: ElevenLabs TTS
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the ElevenLabs TTS model.
  demonstrates:
  - Using the ElevenLabs TTS model.
- file_path: pipeline-tts/only_greet.py
  title: Only Greet
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: beginner
  description: Greets the user when they join the room, but doesn't respond to anything else.
  demonstrates:
  - This agent only has TTS, so it can only speak, not listen or think.
- file_path: pipeline-tts/openai_tts.py
  title: OpenAI TTS
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the OpenAI TTS model.
  demonstrates:
  - Using the OpenAI TTS model.
- file_path: pipeline-tts/playai_tts.py
  title: PlayAI TTS
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the PlayAI TTS model.
  demonstrates:
  - Using the PlayAI TTS model.
- file_path: pipeline-tts/rime_tts.py
  title: Rime TTS
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to use the Rime TTS model.
  demonstrates:
  - Using the Rime TTS model.
- file_path: pipeline-tts/short_replies_only.py
  title: Short Replies Only
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: beginner
  description: Shows how to override the default TTS node to only respond with short replies based on the number of chunks.
  demonstrates:
  - Using the `tts_node` method to override the default TTS node and add custom logic to only respond with short replies.
  - Using the `session.interrupt` method to interrupt the agent if it's taking too long to respond, and then informing the
    user with `session.say`
- file_path: pipeline-tts/tts_comparison/tts_comparison.py
  title: TTS Comparison
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Switches between different TTS providers using function tools.
  demonstrates:
  - Using function tools to switch between different TTS providers.
  - Each function tool returns a new agent with the same instructions, but with a different TTS provider.
- file_path: pipeline-tts/tts_node.py
  title: TTS Node Override
  category: pipeline-tts
  tags:
  - pipeline-tts
  - openai
  - deepgram
  difficulty: intermediate
  description: Shows how to override the default TTS node to do replacements on the output.
  demonstrates:
  - Using the `tts_node` method to override the default TTS node and add custom logic to do replacements on the output, like
    replacing "lol" with "<laughs>".
